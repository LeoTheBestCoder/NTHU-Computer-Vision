{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0MrEVoVmhOy"
      },
      "source": [
        "# Computer Vision Homework 3: Big vs Small Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0hnrUlYrGWS"
      },
      "source": [
        "## Brief"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_zuWZp5rSyN"
      },
      "source": [
        "Due date: Nov 16, 2022\n",
        "\n",
        "Required files: `homework-3.ipynb`, `report.pdf`\n",
        "\n",
        "To download the jupyter notebook from colab, you can refer to the colab tutorial we gave.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om7423NauKQ6"
      },
      "source": [
        "## Codes for Problem 1 and Problem 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX6pBqvV6RCq"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "73wanLwflUdb"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import os\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler\n",
        "from torchvision import transforms, models, datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtXEq_Yx5j-L"
      },
      "source": [
        "### Check GPU Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Yz3wOsYwmEz8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using {device} device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zbpaGDdwnX9g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA TITAN X (Pascal) (UUID: GPU-08bb949b-ba00-8984-874f-5599aaa811fd)\n"
          ]
        }
      ],
      "source": [
        "! nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAoPtdOR5ojk"
      },
      "source": [
        "### Set the Seed to Reproduce the Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Wphy638XBNj-"
      },
      "outputs": [],
      "source": [
        "def set_all_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "set_all_seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLmcH3NAH4wq"
      },
      "source": [
        "### Create Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5VHp_O3_JgZE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Pad(4, padding_mode='reflect'),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='data', train=True, download=True, transform=train_transform)\n",
        "valid_dataset = datasets.CIFAR10(root='data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
        "\n",
        "sixteenth_train_sampler = RandomSampler(train_dataset, num_samples=len(train_dataset)//16)\n",
        "half_train_sampler = RandomSampler(train_dataset, num_samples=len(train_dataset)//2)\n",
        "\n",
        "sixteenth_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=sixteenth_train_sampler)\n",
        "half_train_dataloader = DataLoader(train_dataset, batch_size=batch_size, sampler=half_train_sampler)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjFDtcWRnFS9"
      },
      "source": [
        "### Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vgZV0CodnFS9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /home/leo/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "# HINT: Remember to change the model to 'resnet50' and the weights to weights=\"IMAGENET1K_V1\" when needed.\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', weights=None)\n",
        "\n",
        "# Background: The original resnet18 is designed for ImageNet dataset to predict 1000 classes.\n",
        "# TODO: Change the output of the model to 10 class.\n",
        "model.fc = nn.Linear(in_features=512, out_features=10, bias=True)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZo50knhnFS_"
      },
      "source": [
        "### Training and Testing Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wlXKJeYWnFTA"
      },
      "outputs": [],
      "source": [
        "# TODO: Fill in the code cell according to the pytorch tutorial we gave.\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    num_batches = len(dataloader)\n",
        "    size = len(dataloader.dataset)\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for X, y in tqdm(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagatopn\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        pred = pred.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "    \n",
        "    avg_epoch_loss = epoch_loss / num_batches\n",
        "    avg_acc = correct / size\n",
        "    return avg_epoch_loss, avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    num_batches = len(dataloader)\n",
        "    size = len(dataloader.dataset)\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in tqdm(dataloader):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            pred = model(X)\n",
        "\n",
        "            epoch_loss += loss_fn(pred, y).item()\n",
        "            pred = pred.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(y.view_as(pred)).sum().item()\n",
        "    \n",
        "    avg_epoch_loss = epoch_loss / num_batches\n",
        "    avg_acc = correct / size\n",
        "\n",
        "    return avg_epoch_loss, avg_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [00:26<00:00,  7.47it/s]\n",
            "100%|██████████| 40/40 [00:01<00:00, 27.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  1: Loss = 1.5156 Acc = 0.45 Test_Loss = 1.3954 Test_Acc = 0.51\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [00:22<00:00,  8.74it/s]\n",
            "100%|██████████| 40/40 [00:01<00:00, 27.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  2: Loss = 1.1640 Acc = 0.58 Test_Loss = 1.1646 Test_Acc = 0.60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [00:22<00:00,  8.76it/s]\n",
            "100%|██████████| 40/40 [00:01<00:00, 27.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  3: Loss = 1.0184 Acc = 0.63 Test_Loss = 1.4253 Test_Acc = 0.53\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [00:22<00:00,  8.71it/s]\n",
            "100%|██████████| 40/40 [00:01<00:00, 27.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  4: Loss = 0.9202 Acc = 0.67 Test_Loss = 1.1245 Test_Acc = 0.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 196/196 [00:22<00:00,  8.73it/s]\n",
            "100%|██████████| 40/40 [00:01<00:00, 27.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch  5: Loss = 0.8578 Acc = 0.70 Test_Loss = 0.8545 Test_Acc = 0.70\n",
            "Done!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_acc = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loss, test_acc = test(valid_dataloader, model, loss_fn)\n",
        "    print(f\"Epoch {epoch + 1:2d}: Loss = {train_loss:.4f} Acc = {train_acc:.2f} Test_Loss = {test_loss:.4f} Test_Acc = {test_acc:.2f}\")\n",
        "print('Done!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iqBGAUm6b5W"
      },
      "source": [
        "## Codes for Problem 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SBFMzPT6cP4"
      },
      "outputs": [],
      "source": [
        "# TODO: Try to achieve the best performance given all training data using whatever model and training strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTSafuelpRYJ"
      },
      "source": [
        "## Problems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZctBdkurpQS"
      },
      "source": [
        "1. (30%) Finish the rest of the codes for Problem 1 and Problem 2 according to the hint. (2 code cells in total.)\n",
        "2. Train small model (resnet18) and big model (resnet50) from scratch on `sixteenth_train_dataloader`, `half_train_dataloader`, and `train_dataloader` respectively.\n",
        "3. (30%) Achieve the best performance given all training data using whatever model and training strategy.  \n",
        "  (You cannot use the model that was pretrained on CIFAR10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "786fQTdk0msC"
      },
      "source": [
        "## Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsd2yTmB0k5t"
      },
      "source": [
        "\n",
        "- (30%) The relationship between the accuracy, model size, and the training dataset size.  \n",
        "    (Total 6 models. Small model trains on the sixteenth, half, and all data. Big model trains on the sixteenth, half, and all data.)\n",
        "- (10%) What if we train the ResNet with ImageNet initialized weights (`weights=\"IMAGENET1K_V1\"`), how would the relationship change?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWDxF-xIueMM"
      },
      "source": [
        "## Credits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sXpmSj2ufkh"
      },
      "source": [
        "1. [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MemcOLK_4ULJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('cvhw3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "f441a40f0ee66cb9bb6aa8e46d424e2bbf99fd41e9a43bc42947592a9029ae9e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
